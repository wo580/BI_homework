{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action1\tcnews 中文文本分类：\n",
    "由清华大学根据新浪新闻RSS订阅频道2005-2011年间的历史数据筛选过滤生成\n",
    "训练集 50000\n",
    "验证集 5000\n",
    "测试集 10000\n",
    "词汇（字） 5000\n",
    "10个分类，包括：'体育', '财经', '房产', '家居', '教育', '科技', '时尚', '时政', '游戏', '娱乐'\"\t\n",
    "\n",
    "1、完成代码（30points）\n",
    "2、结果正确（30points）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from model import TextRNN\n",
    "from cnews_loader import read_vocab, read_category, process_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置数据\n",
    "train_file = 'cnews.train.txt'\n",
    "test_file = 'cnews.test.txt'\n",
    "val_file = 'cnews.val.txt'\n",
    "vocab_file = 'cnews.vocab.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Train_Epoch):\n",
    "    model = TextRNN().cuda()\n",
    "    # 定义损失函数\n",
    "    Loss = nn.MultiLabelSoftMarginLoss()\n",
    "    # 定义优化器\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    # 训练\n",
    "    for epoch in range(Train_Epoch):\n",
    "        print('epoch=', epoch)\n",
    "        # 分批训练\n",
    "        for step, (x_batch, y_batch) in enumerate(train_loader):\n",
    "            x = x_batch.cuda()\n",
    "            y = y_batch.cuda()\n",
    "            out = model(x)\n",
    "            loss = Loss(out, y)\n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # 计算准确率\n",
    "            accuracy = np.mean((torch.argmax(out, 1) == torch.argmax(y, 1)).cpu().numpy())\n",
    "        print('train loss=', loss)\n",
    "        print('train accuracy:', accuracy)\n",
    "        # 对模型进行验证\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            for step, (x_batch, y_batch) in enumerate(val_loader):\n",
    "                x = x_batch.cuda()\n",
    "                y = y_batch.cuda()\n",
    "                out = model(x)\n",
    "                accuracy = np.mean((torch.argmax(out, 1) == torch.argmax(y, 1)).cpu().numpy())\n",
    "                if accuracy > best_val_acc:\n",
    "                    torch.save(model, \"model.pkl\")\n",
    "                    best_val_acc = accuracy\n",
    "                    print('model.pkl saved')\n",
    "                    print('val accuracy:', accuracy)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取文本的类别及其对应id的字典\n",
    "categories, cat_to_id = read_category()\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取训练文本中所有出现过的字及其所对应的id\n",
    "words, word_to_id = read_vocab('cnews.vocab.txt')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取训练数据每个字的id和对应标签的one-hot形式\n",
    "x_train, y_train = process_file(train_file, word_to_id, cat_to_id, 600)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = process_file(val_file, word_to_id, cat_to_id, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data#将数据分批次需要用到\n",
    "# 设置GPU\n",
    "cuda = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = torch.LongTensor(x_train), torch.Tensor(y_train)\n",
    "x_val, y_val = torch.LongTensor(x_val), torch.Tensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练参数设置\n",
    "Batch_Size = 256 #设置批次大小\n",
    "Train_Epoch = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Data.TensorDataset(x_train, y_train)\n",
    "train_loader = Data.DataLoader(dataset=train_dataset, batch_size=Batch_Size, shuffle=True)\n",
    "val_dataset = Data.TensorDataset(x_val, y_val)\n",
    "val_loader = Data.DataLoader(dataset=val_dataset, batch_size=Batch_Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "model = train(Train_Epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
