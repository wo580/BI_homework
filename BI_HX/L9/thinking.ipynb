{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking1\t常用的文本分类方法都有哪些\t\t\n",
    "简要说明常用的文本分类方法（20points）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习：朴素贝叶斯，支持向量机，K近邻，决策树\n",
    "深度学习：CNN,RNN,fasttext，lstm\n",
    "\n",
    "1.朴素贝叶斯分类：以自变量之间的独立（条件特征独立）性和连续变量的正态性假设为前提,根据某些个先验概率计算Y变量属于某个类别的后验概率;\n",
    "2.支持向量机（SVM）：(拍案而起)将低维数据映射到高维，找到一个超平面，实现二分类；\n",
    "3.KNN文本分类：通过给定一个未标注文档，分类系统在训练集中查找与它距离最接近的k篇相邻(相似或相同)标注文档，然后根据这k篇邻近文档的分类标注来确定文档的类别；\n",
    "4.决策树：是一种基于训练学习方法获取分类规则的常见分类模型，它建立对象属性与对象值之间的一种映射。通过构造决策树来对未标注文本进行分类判别。常用的决策树方法包括CART 算法、ID3、C4.5、CHAID 等；\n",
    "\n",
    "5.卷积神经网络（CNN）和递归神经网络（RNN）\n",
    "快速文本（fast Text）：句子中所有的词向量进行平均（某种意义上可以理解为只有一个avg pooling特殊CNN），然后直接连接一个softmax 层进行分类；\n",
    "文本卷积神经网络（Text CNN）：利用CNN来提取句子中类似n-gram 的关键信息；\n",
    "文本循环神经网络（Text RNN）：利用RNN循环神经网络解决文本分类问题；\n",
    "\n",
    "LSTM，Long Short-Term Memory，长短记忆网络：LSTM是RNN的升级版本，可以避免常规RNN的梯度消失，在工业界有广泛应用；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking2\tRNN为什么会出现梯度消失\t\t\n",
    "能简要说明RNN梯度消失的原因（20points）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN梯度消失是因为激活函数tanh函数的倒数在0到1之间，反向传播时更新前面时刻的参数时，当参数W初始化为小于1的数，则多个(tanh函数’* W)相乘，将导致求得的偏导极小（小于1的数连乘），从而导致梯度消失"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
