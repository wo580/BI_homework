{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action1\t\"使用任何神经网络框架，对CIFAR-10进行分类\n",
    "http://www.cs.toronto.edu/~kriz/cifar.html\n",
    "训练集 50000，测试集 10000\n",
    "图像大小 32*32 彩色\n",
    "10个分类：ariplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\"\t\t\t\"1、完成代码（30points）\n",
    "2、使用ResNet, DenseNet或其他网络（20points）\n",
    "3、Accuracy >90% （20points）\"\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#读取数据                                     \n",
    "train_data = datasets.CIFAR10(root=\"./cifar10\", train=True, #训练集\n",
    "                              transform=transforms.ToTensor(),# 将PIL Image或者numpy.ndarray转化为torch.FloatTensor，shape为(C,H,W)，并且归一化到[0.0, 1.0]\n",
    "                              download=True)\n",
    "                                               \n",
    "test_data = datasets.CIFAR10(root=\"./cifar10\", train=False,  #测试集\n",
    "                             transform=transforms.ToTensor(), \n",
    "                             download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test_data.data.shape)\n",
    "print(train_data.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#输出图像\n",
    "# img = transforms.ToPILImage()(train_data[6][0])\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "\n",
    "temp = train_data[6][0].numpy()\n",
    "#print(temp.shape)\n",
    "temp = temp.transpose(1, 2, 0)\n",
    "print(temp.shape)\n",
    "plt.imshow(temp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用DataLoader进行分批处理\n",
    "# 超参数定义\n",
    "EPOCH = 10               # 训练epoch次数\n",
    "BATCH_SIZE = 128         # 分批训练的数量\n",
    "LR = 0.001              # 学习率\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to C:\\Users\\Administrator/.cache\\torch\\hub\\checkpoints\\resnet34-333f7ec4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0da4176c70241fe9dcb7f9927606f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87306240.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#model = torchvision.models.resnet18(pretrained=True) # 10000张测试图像准确率:68.4300%\n",
    "#model = torchvision.models.resnet18(pretrained=False) #10000张测试图像准确率:71.3800%\n",
    "model = torchvision.models.resnet34(pretrained=True) # 10000张测试图像准确率:71.3800%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#优化器\n",
    "#optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)#10000张测试图像准确率:74.7800%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定义device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 loss: 0.1422 time 65.6111\n",
      "epoch2 loss: 0.2208 time 65.5989\n",
      "epoch3 loss: 0.1373 time 65.6534\n",
      "epoch4 loss: 0.1804 time 65.6720\n",
      "epoch5 loss: 0.2250 time 65.6001\n",
      "epoch6 loss: 0.1677 time 65.6465\n",
      "epoch7 loss: 0.2287 time 65.6360\n",
      "epoch8 loss: 0.1393 time 65.6477\n",
      "epoch9 loss: 0.3064 time 65.6838\n",
      "epoch10 loss: 0.2447 time 65.6602\n"
     ]
    }
   ],
   "source": [
    "#训练\n",
    "for epoch in range(EPOCH):\n",
    "    start_time = time.time()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        # 计算损失函数\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 清空上一轮梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 参数更新\n",
    "        optimizer.step()\n",
    "    print(\"epoch{} loss:{: .4f} time{: .4f}\".format(epoch+1, loss.item(), time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar10_resnet.pt saved\n"
     ]
    }
   ],
   "source": [
    "#保存训练模型\n",
    "file_name = \"cifar10_resnet.pt\"\n",
    "torch.save(model, file_name)\n",
    "print(file_name + \" saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试\n",
    "model = torch.load(file_name)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct, total = 0, 0\n",
    "for data in test_loader:\n",
    "    images, labels = data\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    # 前向传播\n",
    "    out = model(images)\n",
    "    # 预测结果\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    # 判断预测结果与实际结果是否一致\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted==labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000张测试图像准确率:74.7800%\n"
     ]
    }
   ],
   "source": [
    "# 输出识别率\n",
    "print(\"10000张测试图像准确率:{:.4f}%\".format(100.0*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000张测试图像准确率:71.3800%\n"
     ]
    }
   ],
   "source": [
    "# 输出识别率\n",
    "print(\"10000张测试图像准确率:{:.4f}%\".format(100.0*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000张测试图像准确率:71.3800%\n"
     ]
    }
   ],
   "source": [
    "# 输出识别率\n",
    "print(\"10000张测试图像准确率:{:.4f}%\".format(100.0*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
